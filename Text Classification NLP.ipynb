{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9909507e",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "This task is going to solve a real-world problem using the concepts learned in Text Classification module.\n",
    "We are going to create a benchmark analysis with different algorithms and feature extractors.\n",
    "\n",
    "### Dataset: \n",
    "Fetch 20 Newsgroups\n",
    "### Algorithms: \n",
    "Logistic Regression, Support Vector Machines, Decision Trees\n",
    "### Feature Extractors: \n",
    "CountVectorizer, Word2Vec, Doc2Vec and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808f09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5465e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories\n",
    "categories = ['alt.atheism', 'talk.religion.misc']\n",
    "\n",
    "# Load the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories= categories)\n",
    "\n",
    "X, y = newsgroups.data, newsgroups.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4abe43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models= {\"SGD\": SGDClassifier(), \"LR\": LogisticRegression(), \"SVM\": SVC(), \"DT\": DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a99d513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters= {\n",
    "    'loss': ['hinge', 'log_loss', 'log'],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'warm_start': [True, False],\n",
    "    'average': [True, False],\n",
    "    \n",
    "    'force_alpha': [True, False],\n",
    "    'fit_prior': [True, False],\n",
    "    \n",
    "    'dual': [True, False],\n",
    "    'C': [0.5, 1, 2],\n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg'],\n",
    "    \n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [3, 5, 7],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'probability': [True, False],\n",
    "    \n",
    "    'criterion': [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    'splitter': [\"best\", \"random\"],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70893fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer:\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# Word2Vec:\n",
    "# Tokenize the text and train a Word2Vec model\n",
    "tokenized_text = [text.split() for text in X_train]\n",
    "word2vec_model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, sg=1)\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # Create an array for the document vectors\n",
    "    doc_vec = []\n",
    "    for word in doc:\n",
    "        if word in word2vec_model.wv:\n",
    "            doc_vec.append(word2vec_model.wv[word])\n",
    "    if not doc_vec:\n",
    "        # If the document is empty, return a zero vector\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    # Calculate the mean of the word vectors\n",
    "    return np.mean(doc_vec, axis=0)\n",
    "X_train_word2vec = [document_vector(word2vec_model, text.split()) for text in X_train]\n",
    "X_test_word2vec = [document_vector(word2vec_model, text.split()) for text in X_test]\n",
    "\n",
    "\n",
    "# Doc2Vec:\n",
    "# Tag documents with unique labels\n",
    "tagged_data = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(X_train)]\n",
    "# Train a Doc2Vec model\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=10)\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "\n",
    "# Infer vector representations for the training and testing data\n",
    "X_train_doc2vec = [doc2vec_model.infer_vector(text.split()) for text in X_train]\n",
    "X_test_doc2vec = [doc2vec_model.infer_vector(text.split()) for text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8abe857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict= {'count': X_train_count, 'word2vec': X_train_word2vec, 'doc2vec': X_train_doc2vec}\n",
    "X_test_dict= {'count': X_test_count, 'word2vec': X_test_word2vec, 'doc2vec': X_test_doc2vec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12b46ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Results= pd.DataFrame(columns= ['ML_model', 'Exr_count', 'Exr_word2vec', 'Exr_doc2vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddbff218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.715\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.639\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.636\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.706\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.623\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.624\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.681\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.623\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best score: 0.623\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best score: 0.627\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best score: 0.614\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "Best score: 0.632\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "for m_name, model in Models.items():\n",
    "    # Setting parameters\n",
    "    #paras = {pa: val for pa, val in parameters.items() if pa in model.get_params()}\n",
    "    paras= {}\n",
    "    for pa , val in parameters.items():\n",
    "            if pa in model.get_params():\n",
    "                paras[pa]= val\n",
    "\n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=paras, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    record = {'ML_model': m_name}\n",
    "\n",
    "    for name, X_train_data in X_train_dict.items():\n",
    "        # Fit the model\n",
    "        grid_search.fit(X= X_train_data, y= y_train)\n",
    "\n",
    "        # Best Score\n",
    "        print(f\"Best score: {round(grid_search.best_score_, 3)}\")\n",
    "\n",
    "        # Recording the results\n",
    "        record['Exr_' + name] = round(grid_search.best_score_, 3)\n",
    "\n",
    "    results_list.append(record)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "Results = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53d7ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML_model</th>\n",
       "      <th>Exr_count</th>\n",
       "      <th>Exr_word2vec</th>\n",
       "      <th>Exr_doc2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ML_model  Exr_count  Exr_word2vec  Exr_doc2vec\n",
       "0      SGD      0.715         0.639        0.636\n",
       "1       LR      0.706         0.623        0.624\n",
       "2      SVM      0.681         0.623        0.623\n",
       "3       DT      0.627         0.614        0.632"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1535ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
